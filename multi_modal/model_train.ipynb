{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataloaders\n",
    "\n",
    "train_loader = create_dataloaders(\"../data/Training/01.원천데이터\", batch_size=8, test_ratio = 0, image_size=160, workers=16)\n",
    "val_loader = create_dataloaders( \"../data/Validation/01.원천데이터\", batch_size=8, test_ratio = 0, image_size=160, workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from vision_model import R2Plus1DNet\n",
    "from sensor_model import FallDetection1DCNN\n",
    "\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {DEVICE} device\")\n",
    "\n",
    "vision_checkpoint = torch.load(\"vision_24_12_13.pth\", map_location=DEVICE)\n",
    "vision_model = R2Plus1DNet(num_classes=1).to(DEVICE)\n",
    "vision_model.load_state_dict(vision_checkpoint['model_state_dict'], strict=False)\n",
    "\n",
    "sensor_checkpoint = torch.load(\"sensor_24_12_15.pth\", map_location=DEVICE)\n",
    "sensor_model = FallDetection1DCNN(num_classes=1).to(DEVICE)\n",
    "sensor_model.load_state_dict(sensor_checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MultiModalNet, self).__init__()\n",
    "        self.video_net = vision_model\n",
    "        self.sensor_net = sensor_model\n",
    "\n",
    "        self.fc_sequence = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, video_x, sensor_x):\n",
    "        video_feat = self.video_net(video_x)\n",
    "        sensor_feat = self.sensor_net(sensor_x)\n",
    "\n",
    "\n",
    "        combined = torch.cat([video_feat, sensor_feat], dim=1)\n",
    "\n",
    "        output = self.fc_sequence(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiModalNet(num_classes=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate=0.0001 \n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "def val(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validating\", leave=False)\n",
    "        for video, sensor, label in progress_bar:\n",
    "            video = video.to(DEVICE)\n",
    "            sensor = sensor.to(DEVICE)\n",
    "            label = label.float().unsqueeze(1).to(DEVICE) \n",
    "\n",
    "            output = model(video, sensor)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predicted = (torch.sigmoid(output) > 0.5).float()\n",
    "            correct_predictions += (predicted == label).sum().item()\n",
    "            total_samples += label.size(0)\n",
    "\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_loss = val_loss / len(val_loader)\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Validation Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%, F1 Score: {f1:.2f}\")\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.1009, Accuracy: 96.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0512, Accuracy: 98.64%, F1 Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[ 566    2]\n",
      " [  29 1675]]\n",
      "Model and parameters saved to ./model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.0277, Accuracy: 99.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0306, Accuracy: 99.38%, F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[ 564    4]\n",
      " [  10 1694]]\n",
      "Model and parameters saved to ./model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.0150, Accuracy: 99.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0389, Accuracy: 99.12%, F1 Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[ 564    4]\n",
      " [  16 1688]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.0106, Accuracy: 99.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0425, Accuracy: 99.03%, F1 Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[ 565    3]\n",
      " [  19 1685]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.0076, Accuracy: 99.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0395, Accuracy: 99.08%, F1 Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[ 563    5]\n",
      " [  16 1688]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.0069, Accuracy: 99.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0423, Accuracy: 99.16%, F1 Score: 0.99\n",
      "Confusion Matrix:\n",
      " [[ 564    4]\n",
      " [  15 1689]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.0044, Accuracy: 99.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0452, Accuracy: 99.34%, F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[ 567    1]\n",
      " [  14 1690]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0027, Accuracy: 99.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0504, Accuracy: 99.25%, F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[ 560    8]\n",
      " [   9 1695]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0050, Accuracy: 99.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0550, Accuracy: 99.30%, F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[ 560    8]\n",
      " [   8 1696]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0023, Accuracy: 99.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0494, Accuracy: 99.43%, F1 Score: 1.00\n",
      "Confusion Matrix:\n",
      " [[ 566    2]\n",
      " [  11 1693]]\n",
      "Model and parameters saved to ./model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, val_loader, num_epochs):\n",
    "    best_val_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
    "\n",
    "        for video, sensor, label in progress_bar:\n",
    "            video = video.to(DEVICE)\n",
    "            sensor = sensor.to(DEVICE)\n",
    "            label = label.float().unsqueeze(1).to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(video, sensor)\n",
    "\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            predicted = (torch.sigmoid(output) > 0.5).float()\n",
    "            correct_predictions += (predicted == label).sum().item()\n",
    "            total_samples += label.size(0)\n",
    "\n",
    "            progress_bar.set_postfix(loss=running_loss / (progress_bar.n + 1))\n",
    "\n",
    "        accuracy = correct_predictions / total_samples * 100\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        avg_val_loss, val_acc = val(model, val_loader, criterion)\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model_save_path = './model.pth'\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_val_loss\n",
    "            }, model_save_path)\n",
    "            print(f\"Model and parameters saved to {model_save_path}\")\n",
    "\n",
    "num_epochs = 10\n",
    "train(model, train_loader, val_loader, num_epochs=num_epochs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
