{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dCVrf2AO5emT"
   },
   "outputs": [],
   "source": [
    "from sensordataset import SensorDataset\n",
    "data_types = ['Segment Acceleration', 'Segment Angular Velocity', 'Sensor Magnetic Field']\n",
    "train_dataset = SensorDataset(input_dir='./sensor_Training', data_types=data_types)\n",
    "val_dataset = SensorDataset(input_dir='./sensor_Validation', data_types=data_types)\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: torch.Size([32, 12, 10, 9])\n"
     ]
    }
   ],
   "source": [
    "for data, label in train_loader:\n",
    "    print(\"data shape:\", data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FallDetection1DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(FallDetection1DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=9, out_channels=16, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=3, stride=3)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        feature_vectors = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            sample_features = []\n",
    "\n",
    "            for j in range(x.size(1)):\n",
    "                sample = x[i, j].unsqueeze(0)\n",
    "                sample = sample.permute(0, 2, 1)\n",
    "\n",
    "                out = self.conv1(sample)\n",
    "                out = self.relu(out)\n",
    "                out = self.pool1(out)\n",
    "\n",
    "                out = self.conv2(out)\n",
    "                out = self.relu(out)\n",
    "                out = self.pool1(out)\n",
    "\n",
    "                out = self.conv3(out)\n",
    "                out = self.relu(out)\n",
    "                out = self.pool1(out)\n",
    "                \n",
    "                pooled_out = torch.mean(out, dim=2)\n",
    "                sample_features.append(pooled_out)\n",
    "\n",
    "            concatenated = torch.cat(sample_features, dim=1)\n",
    "            feature_vectors.append(concatenated)\n",
    "\n",
    "        feature_vectors = torch.cat(feature_vectors, dim=0)\n",
    "        feature_vectors = self.pool2(feature_vectors)\n",
    "        x = self.fc(feature_vectors)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "fhm8cl525emX"
   },
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "model = FallDetection1DCNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "neelUlpS5emY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "f1Zz8tr55emY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Training Loss: 0.6196, Training Accuracy: 0.6408\n",
      "Epoch [1/50], Validation Loss: 0.5296, Validation Accuracy: 0.7500\n",
      "Confusion Matrix:\n",
      " [[  0  71]\n",
      " [  0 213]]\n",
      "Precision: 0.7500, Recall: 1.0000, F1-Score: 0.8571\n",
      "Best model updated and saved!\n",
      "Epoch [2/50], Training Loss: 0.5216, Training Accuracy: 0.7493\n",
      "Epoch [2/50], Validation Loss: 0.4918, Validation Accuracy: 0.7500\n",
      "Confusion Matrix:\n",
      " [[  0  71]\n",
      " [  0 213]]\n",
      "Precision: 0.7500, Recall: 1.0000, F1-Score: 0.8571\n",
      "Best model updated and saved!\n",
      "Epoch [3/50], Training Loss: 0.4746, Training Accuracy: 0.7493\n",
      "Epoch [3/50], Validation Loss: 0.4363, Validation Accuracy: 0.7500\n",
      "Confusion Matrix:\n",
      " [[  0  71]\n",
      " [  0 213]]\n",
      "Precision: 0.7500, Recall: 1.0000, F1-Score: 0.8571\n",
      "Best model updated and saved!\n",
      "Epoch [4/50], Training Loss: 0.4210, Training Accuracy: 0.7661\n",
      "Epoch [4/50], Validation Loss: 0.3903, Validation Accuracy: 0.8134\n",
      "Confusion Matrix:\n",
      " [[ 22  49]\n",
      " [  4 209]]\n",
      "Precision: 0.8101, Recall: 0.9812, F1-Score: 0.8875\n",
      "Best model updated and saved!\n",
      "Epoch [5/50], Training Loss: 0.3754, Training Accuracy: 0.8319\n",
      "Epoch [5/50], Validation Loss: 0.3431, Validation Accuracy: 0.8627\n",
      "Confusion Matrix:\n",
      " [[ 37  34]\n",
      " [  5 208]]\n",
      "Precision: 0.8595, Recall: 0.9765, F1-Score: 0.9143\n",
      "Best model updated and saved!\n",
      "Epoch [6/50], Training Loss: 0.3305, Training Accuracy: 0.8544\n",
      "Epoch [6/50], Validation Loss: 0.3064, Validation Accuracy: 0.8873\n",
      "Confusion Matrix:\n",
      " [[ 46  25]\n",
      " [  7 206]]\n",
      "Precision: 0.8918, Recall: 0.9671, F1-Score: 0.9279\n",
      "Best model updated and saved!\n",
      "Epoch [7/50], Training Loss: 0.2864, Training Accuracy: 0.8795\n",
      "Epoch [7/50], Validation Loss: 0.2564, Validation Accuracy: 0.8979\n",
      "Confusion Matrix:\n",
      " [[ 51  20]\n",
      " [  9 204]]\n",
      "Precision: 0.9107, Recall: 0.9577, F1-Score: 0.9336\n",
      "Best model updated and saved!\n",
      "Epoch [8/50], Training Loss: 0.2485, Training Accuracy: 0.8994\n",
      "Epoch [8/50], Validation Loss: 0.2271, Validation Accuracy: 0.9155\n",
      "Confusion Matrix:\n",
      " [[ 60  11]\n",
      " [ 13 200]]\n",
      "Precision: 0.9479, Recall: 0.9390, F1-Score: 0.9434\n",
      "Best model updated and saved!\n",
      "Epoch [9/50], Training Loss: 0.2193, Training Accuracy: 0.9122\n",
      "Epoch [9/50], Validation Loss: 0.1911, Validation Accuracy: 0.9331\n",
      "Confusion Matrix:\n",
      " [[ 58  13]\n",
      " [  6 207]]\n",
      "Precision: 0.9409, Recall: 0.9718, F1-Score: 0.9561\n",
      "Best model updated and saved!\n",
      "Epoch [10/50], Training Loss: 0.1890, Training Accuracy: 0.9294\n",
      "Epoch [10/50], Validation Loss: 0.1988, Validation Accuracy: 0.9225\n",
      "Confusion Matrix:\n",
      " [[ 68   3]\n",
      " [ 19 194]]\n",
      "Precision: 0.9848, Recall: 0.9108, F1-Score: 0.9463\n",
      "Epoch [11/50], Training Loss: 0.1735, Training Accuracy: 0.9378\n",
      "Epoch [11/50], Validation Loss: 0.1475, Validation Accuracy: 0.9613\n",
      "Confusion Matrix:\n",
      " [[ 67   4]\n",
      " [  7 206]]\n",
      "Precision: 0.9810, Recall: 0.9671, F1-Score: 0.9740\n",
      "Best model updated and saved!\n",
      "Epoch [12/50], Training Loss: 0.1506, Training Accuracy: 0.9510\n",
      "Epoch [12/50], Validation Loss: 0.1551, Validation Accuracy: 0.9472\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [ 14 199]]\n",
      "Precision: 0.9950, Recall: 0.9343, F1-Score: 0.9637\n",
      "Epoch [13/50], Training Loss: 0.1385, Training Accuracy: 0.9523\n",
      "Epoch [13/50], Validation Loss: 0.1335, Validation Accuracy: 0.9577\n",
      "Confusion Matrix:\n",
      " [[ 69   2]\n",
      " [ 10 203]]\n",
      "Precision: 0.9902, Recall: 0.9531, F1-Score: 0.9713\n",
      "Best model updated and saved!\n",
      "Epoch [14/50], Training Loss: 0.1269, Training Accuracy: 0.9603\n",
      "Epoch [14/50], Validation Loss: 0.1347, Validation Accuracy: 0.9542\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [ 12 201]]\n",
      "Precision: 0.9950, Recall: 0.9437, F1-Score: 0.9687\n",
      "Epoch [15/50], Training Loss: 0.1181, Training Accuracy: 0.9603\n",
      "Epoch [15/50], Validation Loss: 0.1175, Validation Accuracy: 0.9648\n",
      "Confusion Matrix:\n",
      " [[ 69   2]\n",
      " [  8 205]]\n",
      "Precision: 0.9903, Recall: 0.9624, F1-Score: 0.9762\n",
      "Best model updated and saved!\n",
      "Epoch [16/50], Training Loss: 0.1094, Training Accuracy: 0.9673\n",
      "Epoch [16/50], Validation Loss: 0.1141, Validation Accuracy: 0.9613\n",
      "Confusion Matrix:\n",
      " [[ 69   2]\n",
      " [  9 204]]\n",
      "Precision: 0.9903, Recall: 0.9577, F1-Score: 0.9737\n",
      "Best model updated and saved!\n",
      "Epoch [17/50], Training Loss: 0.1072, Training Accuracy: 0.9625\n",
      "Epoch [17/50], Validation Loss: 0.1272, Validation Accuracy: 0.9507\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [ 13 200]]\n",
      "Precision: 0.9950, Recall: 0.9390, F1-Score: 0.9662\n",
      "Epoch [18/50], Training Loss: 0.1001, Training Accuracy: 0.9669\n",
      "Epoch [18/50], Validation Loss: 0.1253, Validation Accuracy: 0.9507\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [ 13 200]]\n",
      "Precision: 0.9950, Recall: 0.9390, F1-Score: 0.9662\n",
      "Epoch [19/50], Training Loss: 0.0925, Training Accuracy: 0.9713\n",
      "Epoch [19/50], Validation Loss: 0.1091, Validation Accuracy: 0.9648\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  9 204]]\n",
      "Precision: 0.9951, Recall: 0.9577, F1-Score: 0.9761\n",
      "Best model updated and saved!\n",
      "Epoch [20/50], Training Loss: 0.0870, Training Accuracy: 0.9722\n",
      "Epoch [20/50], Validation Loss: 0.1012, Validation Accuracy: 0.9683\n",
      "Confusion Matrix:\n",
      " [[ 69   2]\n",
      " [  7 206]]\n",
      "Precision: 0.9904, Recall: 0.9671, F1-Score: 0.9786\n",
      "Best model updated and saved!\n",
      "Epoch [21/50], Training Loss: 0.0833, Training Accuracy: 0.9731\n",
      "Epoch [21/50], Validation Loss: 0.1070, Validation Accuracy: 0.9683\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  8 205]]\n",
      "Precision: 0.9951, Recall: 0.9624, F1-Score: 0.9785\n",
      "Epoch [22/50], Training Loss: 0.0836, Training Accuracy: 0.9722\n",
      "Epoch [22/50], Validation Loss: 0.0903, Validation Accuracy: 0.9754\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  6 207]]\n",
      "Precision: 0.9952, Recall: 0.9718, F1-Score: 0.9834\n",
      "Best model updated and saved!\n",
      "Epoch [23/50], Training Loss: 0.0747, Training Accuracy: 0.9784\n",
      "Epoch [23/50], Validation Loss: 0.1017, Validation Accuracy: 0.9648\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  9 204]]\n",
      "Precision: 0.9951, Recall: 0.9577, F1-Score: 0.9761\n",
      "Epoch [24/50], Training Loss: 0.0708, Training Accuracy: 0.9779\n",
      "Epoch [24/50], Validation Loss: 0.1109, Validation Accuracy: 0.9577\n",
      "Confusion Matrix:\n",
      " [[ 71   0]\n",
      " [ 12 201]]\n",
      "Precision: 1.0000, Recall: 0.9437, F1-Score: 0.9710\n",
      "Epoch [25/50], Training Loss: 0.0671, Training Accuracy: 0.9797\n",
      "Epoch [25/50], Validation Loss: 0.0901, Validation Accuracy: 0.9754\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  6 207]]\n",
      "Precision: 0.9952, Recall: 0.9718, F1-Score: 0.9834\n",
      "Best model updated and saved!\n",
      "Epoch [26/50], Training Loss: 0.0641, Training Accuracy: 0.9806\n",
      "Epoch [26/50], Validation Loss: 0.0884, Validation Accuracy: 0.9718\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  7 206]]\n",
      "Precision: 0.9952, Recall: 0.9671, F1-Score: 0.9810\n",
      "Best model updated and saved!\n",
      "Epoch [27/50], Training Loss: 0.0606, Training Accuracy: 0.9828\n",
      "Epoch [27/50], Validation Loss: 0.0883, Validation Accuracy: 0.9718\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  7 206]]\n",
      "Precision: 0.9952, Recall: 0.9671, F1-Score: 0.9810\n",
      "Best model updated and saved!\n",
      "Epoch [28/50], Training Loss: 0.0575, Training Accuracy: 0.9828\n",
      "Epoch [28/50], Validation Loss: 0.1076, Validation Accuracy: 0.9613\n",
      "Confusion Matrix:\n",
      " [[ 71   0]\n",
      " [ 11 202]]\n",
      "Precision: 1.0000, Recall: 0.9484, F1-Score: 0.9735\n",
      "Epoch [29/50], Training Loss: 0.0547, Training Accuracy: 0.9850\n",
      "Epoch [29/50], Validation Loss: 0.0846, Validation Accuracy: 0.9754\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  6 207]]\n",
      "Precision: 0.9952, Recall: 0.9718, F1-Score: 0.9834\n",
      "Best model updated and saved!\n",
      "Epoch [30/50], Training Loss: 0.0617, Training Accuracy: 0.9819\n",
      "Epoch [30/50], Validation Loss: 0.0947, Validation Accuracy: 0.9648\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  9 204]]\n",
      "Precision: 0.9951, Recall: 0.9577, F1-Score: 0.9761\n",
      "Epoch [31/50], Training Loss: 0.0513, Training Accuracy: 0.9863\n",
      "Epoch [31/50], Validation Loss: 0.0907, Validation Accuracy: 0.9683\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  8 205]]\n",
      "Precision: 0.9951, Recall: 0.9624, F1-Score: 0.9785\n",
      "Epoch [32/50], Training Loss: 0.0505, Training Accuracy: 0.9863\n",
      "Epoch [32/50], Validation Loss: 0.0896, Validation Accuracy: 0.9718\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [  7 206]]\n",
      "Precision: 0.9952, Recall: 0.9671, F1-Score: 0.9810\n",
      "Epoch [33/50], Training Loss: 0.0476, Training Accuracy: 0.9863\n",
      "Epoch [33/50], Validation Loss: 0.1094, Validation Accuracy: 0.9542\n",
      "Confusion Matrix:\n",
      " [[ 70   1]\n",
      " [ 12 201]]\n",
      "Precision: 0.9950, Recall: 0.9437, F1-Score: 0.9687\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m samples, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     12\u001b[0m     samples, labels \u001b[38;5;241m=\u001b[39m samples\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/forFace/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forFace/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 30\u001b[0m, in \u001b[0;36mFallDetection1DCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     28\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(out)\n\u001b[0;32m---> 30\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     32\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/forFace/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forFace/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/forFace/lib/python3.11/site-packages/torch/nn/modules/conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/forFace/lib/python3.11/site-packages/torch/nn/modules/conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "num_epochs = 30 \n",
    "best_val_loss = float('inf') \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for samples, labels in train_loader:\n",
    "        samples, labels = samples.to(device), labels.float().to(device).unsqueeze(1)\n",
    "\n",
    "        outputs = model(samples)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * samples.size(0) \n",
    "\n",
    "        predictions = (outputs >= 0.5).float()  \n",
    "        correct_train += (predictions == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {epoch_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    model.eval() \n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "\n",
    "    all_val_labels = []\n",
    "    all_val_predictions = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for val_samples, val_labels in val_loader:\n",
    "            val_samples, val_labels = val_samples.to(device), val_labels.float().to(device).unsqueeze(1)\n",
    "\n",
    "            val_outputs = model(val_samples)\n",
    "            val_loss += criterion(val_outputs, val_labels).item() * val_samples.size(0)\n",
    "\n",
    "            val_predictions = (val_outputs >= 0.5).float()\n",
    "            correct_val += (val_predictions == val_labels).sum().item()\n",
    "            total_val += val_labels.size(0)\n",
    "\n",
    "            all_val_labels.extend(val_labels.cpu().numpy())\n",
    "            all_val_predictions.extend(val_predictions.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    cm = confusion_matrix(all_val_labels, all_val_predictions)\n",
    "    precision = precision_score(all_val_labels, all_val_predictions)\n",
    "    recall = recall_score(all_val_labels, all_val_predictions)\n",
    "    f1 = f1_score(all_val_labels, all_val_predictions)\n",
    "\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './best_model.pth')\n",
    "        print(\"Best model updated and saved!\")\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj_24_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
