{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Plus1D_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None, stride=1):\n",
    "        super(R2Plus1D_Block, self).__init__()\n",
    "        if mid_channels is None:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        self.spatial_conv = nn.Conv3d(\n",
    "            in_channels,\n",
    "            mid_channels,\n",
    "            kernel_size=(1, 3, 3),\n",
    "            stride=(1, stride, stride),\n",
    "            padding=(0, 1, 1),\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn1 = nn.BatchNorm3d(mid_channels)\n",
    "\n",
    "        self.temporal_conv = nn.Conv3d(\n",
    "            mid_channels,\n",
    "            out_channels,\n",
    "            kernel_size=(3, 1, 1),\n",
    "            stride=(stride, 1, 1),\n",
    "            padding=(1, 0, 0),\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.spatial_conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.temporal_conv(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Plus1DNet(nn.Module):\n",
    "    def __init__(self, num_classes=400):\n",
    "        super(R2Plus1DNet, self).__init__()\n",
    "        self.layer1 = R2Plus1D_Block(3, 64, stride=1)\n",
    "        self.layer2 = R2Plus1D_Block(64, 128, stride=2)\n",
    "        self.layer3 = R2Plus1D_Block(128, 128, stride=2)\n",
    "        self.layer4 = R2Plus1D_Block(128, 64, stride=2)\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {DEVICE} device\")\n",
    "model = R2Plus1DNet(num_classes=1).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_for_fact_CNN import create_dataloaders\n",
    "\n",
    "data_dir = '../data/Training/01.원천데이터/이미지'\n",
    "train_dataloader = create_dataloaders(data_dir, test_ratio = 0, batch_size=8, image_size = 160, workers=16)\n",
    "data_dir = '../data/Validation/01.원천데이터/이미지'\n",
    "val_dataloader = create_dataloaders(data_dir, test_ratio = 0, batch_size=8, image_size = 160, workers = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 0.0001\n",
    "EPOCHS = 10\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "def val(model, val_loader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for img, labels in tqdm(val_loader):\n",
    "            img = img.to(device)\n",
    "            labels = labels.to(device, dtype=torch.float32)\n",
    "\n",
    "            output = model(img)\n",
    "            loss = criterion(output.view(-1), labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = (output.view(-1) > 0.5).float()\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = correct_preds / total_preds * 100\n",
    "\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, optimizer, criterion, device='cpu', epoches=10):\n",
    "    model.train()\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(epoches):\n",
    "        epoch_loss = 0.0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        for img, labels in tqdm(train_loader):\n",
    "            img = img.to(device)\n",
    "            labels = labels.to(device, dtype=torch.float32) \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(img)\n",
    "            \n",
    "            loss = criterion(output.view(-1), labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            preds = (output.view(-1) > 0.5).float()\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        accuracy = correct_preds / total_preds * 100\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epoches}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        avg_val_loss, val_acc = val(model, val_loader, criterion, device)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            model_save_path = 'model.pth'\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': EPOCHS,\n",
    "                'loss': avg_loss\n",
    "            }, model_save_path)\n",
    "            print(f\"Model and parameters saved to {model_save_path}\")\n",
    "            \n",
    "    return avg_val_loss, val_acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:51<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.4385, Accuracy: 82.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:05<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2773, Validation Accuracy: 94.67%\n",
      "Model and parameters saved to model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:20<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.2279, Accuracy: 90.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:06<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1883, Validation Accuracy: 93.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:22<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.1422, Accuracy: 94.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:05<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1603, Validation Accuracy: 94.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:22<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.1001, Accuracy: 96.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:01<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1553, Validation Accuracy: 96.96%\n",
      "Model and parameters saved to model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:23<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.0754, Accuracy: 97.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:07<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1168, Validation Accuracy: 96.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:21<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.0717, Accuracy: 97.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:03<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0897, Validation Accuracy: 97.36%\n",
      "Model and parameters saved to model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:23<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.0549, Accuracy: 98.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1182, Validation Accuracy: 95.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:22<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.0517, Accuracy: 98.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:02<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1279, Validation Accuracy: 97.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:23<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.0453, Accuracy: 98.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:04<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1000, Validation Accuracy: 98.28%\n",
      "Model and parameters saved to model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266/2266 [21:22<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.0391, Accuracy: 98.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 284/284 [02:06<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1501, Validation Accuracy: 97.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_loss, acc = train(model, train_dataloader, val_dataloader, optimizer, criterion, device=DEVICE, epoches=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
